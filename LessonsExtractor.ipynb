{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/z4n0/LessonsExtractor/blob/main/LessonsExtractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0kO_tqcov-aI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f8d3a61-d9f9-4eba-ce93-744ea697bd3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls /content/drive/MyDrive/lessonsExtractor"
      ],
      "metadata": {
        "id": "hl37iVQ3wAM7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebd4057d-c083-4924-ac9a-2c6838b51efb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;36m/content/drive/MyDrive/lessonsExtractor\u001b[0m@\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: TURN ON THE T4 GPU"
      ],
      "metadata": {
        "id": "tGkXrIYPFgQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "e-DxNH_1u1Wt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb0217f3-0f1a-43c7-cf6a-5b36ad288293"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/lessonsExtractor/"
      ],
      "metadata": {
        "id": "4ccQmw_FyoBn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c204ce1-2952-4d5e-ddf6-cd2ac3f69a0d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1bQb8gi6zCwEeUgzwHQLPETmzfh9dMdVq/lessonsExtractor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "eQo9mJvpypKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e097b5-bf27-4f96-9830-eeed3863c6dc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9_Semantic_Segmentation_converted.mp4  converted_video.mp4  LessonsExtractor.ipynb  \u001b[0m\u001b[01;34mslides\u001b[0m/\n",
            "9_Semantic_Segmentation.mp4            CSR-20221124.mp4     output.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## conversion from mkv to mp4"
      ],
      "metadata": {
        "id": "DJW17lm8zjOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i prova.mkv"
      ],
      "metadata": {
        "id": "vAakNFvfAiKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!ffmpeg -i prova.mkv -c:v libx264 -c:a aac prova_converted.mp4"
      ],
      "metadata": {
        "id": "H7VWtpUyzhah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "reduce quality and bit rate to help the code run faster"
      ],
      "metadata": {
        "id": "69BFKqis0FAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i prova.mkv -s 1280x720 -b:v 1M -c:v libx264 -c:a aac prova_converted.mp4"
      ],
      "metadata": {
        "id": "s1ULV6OC0EG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CODE TO REDUCE QUALITY AND BIT RATE AND SELECT A PIECE OF THE MP4 VIDEO"
      ],
      "metadata": {
        "id": "lEh4fvV54lY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#check if ffmpeg is compatible for hw accelleration\n",
        "\n",
        "TURN ON THE T4 GPU!!\n",
        "\n",
        "A typical successful output snippet might start like this:\n"
      ],
      "metadata": {
        "id": "QVoSM5g2EfL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Encoder h264_nvenc [NVIDIA NVENC H.264 encoder]:\n",
        "    General capabilities: delay hardware\n",
        "    Threading capabilities: none\n",
        "    Supported pixel formats: nv12 p010le yuv444p nv16 yuv444p16le bgr0 rgb0 ...\n",
        "    ...\n"
      ],
      "metadata": {
        "id": "3GzWKPyaEn2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#code to check if you can use accelleration\n",
        "!ffmpeg -h encoder=h264_nvenc"
      ],
      "metadata": {
        "id": "xf6mphRYEII0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check if the tpu is on\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoSA9mYqF9uS",
        "outputId": "2a2f851a-5a50-4fde-e77e-c82588c909b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 16 17:06:47 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZvvJtPGlBLP",
        "outputId": "ea758a21-6041-4f2c-a01a-75fe4d4d6e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "converted_video.mp4  CSR-20221124.mp4  lessonsExtractor.ipynb  \u001b[0m\u001b[01;34mslides\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#slide extractor"
      ],
      "metadata": {
        "id": "HWRxLyAGhTmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "CdA19uZ0h6Ja"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_video_path = '/content/drive/MyDrive/lessonsExtractor/9_Semantic_Segmentation.mp4'\n",
        "\n",
        "# Extract base name and remove extension to form the new output file name\n",
        "base_name = os.path.basename(input_video_path)\n",
        "file_name_without_ext = os.path.splitext(base_name)[0]\n",
        "output_video_path = f\"/content/drive/MyDrive/lessonsExtractor/{file_name_without_ext}_converted.mp4\"\n",
        "resolution = \"1280x720\"\n",
        "bitrate = \"1M\"\n",
        "start_time = \"00:40:00\"  # Start at 40 minutes"
      ],
      "metadata": {
        "id": "7WLs5IdG4k7P"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#duration = \"00:30:00\"  # Duration of 50 minutes, will stop at the end of the video if it's shorter\n",
        "\n",
        "# Standard FFmpeg command\n",
        "#!ffmpeg -ss {start_time} -i {input_video_path} -t {duration} -s {resolution} -b:v {bitrate} -c:v libx264 -c:a aac {output_video_path}\n",
        "\n",
        "# GPU accelerated version\n",
        "#!ffmpeg -hwaccel cuda -ss {start_time} -i {input_video_path} -s {resolution} -b:v {bitrate} -c:v h264_nvenc -c:a aac {output_video_path}\n",
        "!ffmpeg -i {input_video_path} -ss {start_time} -s {resolution} -b:v {bitrate} -c:v h264_nvenc -c:a aac {output_video_path}"
      ],
      "metadata": {
        "id": "cnEQxoQR4O80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "you should see the new converted_video.mp4 here. let's check!"
      ],
      "metadata": {
        "id": "lPhc983z6MQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9wwJVTh02fr",
        "outputId": "c6c049bd-66d2-4e5d-f798-939aa6259834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TO BE DELETED?\n",
        "def sum_time(time1, time2):\n",
        "    # Convert time to seconds\n",
        "    def time_to_seconds(time_str):\n",
        "        h, m, s = map(int, time_str.split(':'))\n",
        "        return h * 3600 + m * 60 + s\n",
        "\n",
        "    # Convert seconds back to time\n",
        "    def seconds_to_time(seconds):\n",
        "        h = seconds // 3600\n",
        "        m = (seconds % 3600) // 60\n",
        "        s = seconds % 60\n",
        "        return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
        "\n",
        "    total_seconds = time_to_seconds(time1) + time_to_seconds(time2)\n",
        "    return seconds_to_time(total_seconds)\n"
      ],
      "metadata": {
        "id": "ujb9RrWf4x3C"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NB: THE PARAMETER THRESHOLD IN DETECT_SLIDES(....) HAS TO BE FINE TUNED FOR EACH VIDEO**\n",
        "\n",
        "the higher the value the more selective it becomes"
      ],
      "metadata": {
        "id": "j0Gdu8QL7bQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_frame(frame, timestamp, output_folder='slides'):\n",
        "    print(sum_time(timestamp, start_time))\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "    filename = f\"{output_folder}/slide_{timestamp}.jpg\"\n",
        "    cv2.imwrite(filename, frame)\n",
        "    print(f\"Saved: {filename}\")\n",
        "\n",
        "def frame_difference(prev_frame, curr_frame):\n",
        "    # Compute the absolute difference between the current frame and the previous frame\n",
        "    diff = cv2.absdiff(prev_frame, curr_frame)\n",
        "    non_zero_count = np.count_nonzero(diff)\n",
        "    return non_zero_count\n",
        "\n",
        "def milliseconds_to_hh_mm_ss(milliseconds):\n",
        "    hours = int(milliseconds / 3600000)\n",
        "    minutes = int((milliseconds % 3600000) / 60000)\n",
        "    seconds = int((milliseconds % 60000) / 1000)\n",
        "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
        "\n",
        "#trashold is to be fine tuned for each video\n",
        "def detect_slides(video_path, threshold=385000, skip_frames=50):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    ret, prev_frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Failed to read the video\")\n",
        "        return []\n",
        "\n",
        "    prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
        "    frame_count = 0\n",
        "    slide_changes = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, curr_frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_count % skip_frames == 0:\n",
        "            gray_frame = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
        "            if frame_difference(prev_frame, gray_frame) > threshold:\n",
        "                timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
        "                timestamp_readable = milliseconds_to_hh_mm_ss(timestamp_ms)\n",
        "                adjusted_timestamp = sum_time(timestamp_readable, start_time)  # Adjust the timestamp\n",
        "                slide_changes.append(adjusted_timestamp)\n",
        "                save_frame(curr_frame, adjusted_timestamp)  # Use adjusted timestamp\n",
        "                prev_frame = gray_frame\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    return slide_changes\n",
        "\n",
        "input_video_path = output_video_path\n",
        "slide_changes = detect_slides(input_video_path)\n",
        "print(f\"Slide changes detected at: {slide_changes}\")"
      ],
      "metadata": {
        "id": "3AjMT6gtu_4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff765638-8a87-4a86-cfdf-6f7f56fa9080"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "01:20:26\n",
            "Saved: slides/slide_00:40:26.jpg\n",
            "01:20:56\n",
            "Saved: slides/slide_00:40:56.jpg\n",
            "01:21:18\n",
            "Saved: slides/slide_00:41:18.jpg\n",
            "01:21:32\n",
            "Saved: slides/slide_00:41:32.jpg\n",
            "01:22:52\n",
            "Saved: slides/slide_00:42:52.jpg\n",
            "01:26:00\n",
            "Saved: slides/slide_00:46:00.jpg\n",
            "01:28:12\n",
            "Saved: slides/slide_00:48:12.jpg\n",
            "01:28:18\n",
            "Saved: slides/slide_00:48:18.jpg\n",
            "01:28:20\n",
            "Saved: slides/slide_00:48:20.jpg\n",
            "01:28:40\n",
            "Saved: slides/slide_00:48:40.jpg\n",
            "01:28:54\n",
            "Saved: slides/slide_00:48:54.jpg\n",
            "01:29:10\n",
            "Saved: slides/slide_00:49:10.jpg\n",
            "01:29:40\n",
            "Saved: slides/slide_00:49:40.jpg\n",
            "01:29:56\n",
            "Saved: slides/slide_00:49:56.jpg\n",
            "01:30:00\n",
            "Saved: slides/slide_00:50:00.jpg\n",
            "01:30:20\n",
            "Saved: slides/slide_00:50:20.jpg\n",
            "01:30:32\n",
            "Saved: slides/slide_00:50:32.jpg\n",
            "01:30:40\n",
            "Saved: slides/slide_00:50:40.jpg\n",
            "01:30:46\n",
            "Saved: slides/slide_00:50:46.jpg\n",
            "01:30:48\n",
            "Saved: slides/slide_00:50:48.jpg\n",
            "01:34:06\n",
            "Saved: slides/slide_00:54:06.jpg\n",
            "01:35:20\n",
            "Saved: slides/slide_00:55:20.jpg\n",
            "01:38:38\n",
            "Saved: slides/slide_00:58:38.jpg\n",
            "01:39:12\n",
            "Saved: slides/slide_00:59:12.jpg\n",
            "01:40:12\n",
            "Saved: slides/slide_01:00:12.jpg\n",
            "01:40:56\n",
            "Saved: slides/slide_01:00:56.jpg\n",
            "01:40:58\n",
            "Saved: slides/slide_01:00:58.jpg\n",
            "01:41:00\n",
            "Saved: slides/slide_01:01:00.jpg\n",
            "01:41:06\n",
            "Saved: slides/slide_01:01:06.jpg\n",
            "01:41:08\n",
            "Saved: slides/slide_01:01:08.jpg\n",
            "01:41:10\n",
            "Saved: slides/slide_01:01:10.jpg\n",
            "01:41:12\n",
            "Saved: slides/slide_01:01:12.jpg\n",
            "01:41:14\n",
            "Saved: slides/slide_01:01:14.jpg\n",
            "01:41:20\n",
            "Saved: slides/slide_01:01:20.jpg\n",
            "01:41:50\n",
            "Saved: slides/slide_01:01:50.jpg\n",
            "01:43:38\n",
            "Saved: slides/slide_01:03:38.jpg\n",
            "01:45:28\n",
            "Saved: slides/slide_01:05:28.jpg\n",
            "01:50:24\n",
            "Saved: slides/slide_01:10:24.jpg\n",
            "01:51:08\n",
            "Saved: slides/slide_01:11:08.jpg\n",
            "01:51:20\n",
            "Saved: slides/slide_01:11:20.jpg\n",
            "01:51:36\n",
            "Saved: slides/slide_01:11:36.jpg\n",
            "01:54:18\n",
            "Saved: slides/slide_01:14:18.jpg\n",
            "01:55:26\n",
            "Saved: slides/slide_01:15:26.jpg\n",
            "01:55:48\n",
            "Saved: slides/slide_01:15:48.jpg\n",
            "01:55:56\n",
            "Saved: slides/slide_01:15:56.jpg\n",
            "01:56:28\n",
            "Saved: slides/slide_01:16:28.jpg\n",
            "01:58:06\n",
            "Saved: slides/slide_01:18:06.jpg\n",
            "01:58:48\n",
            "Saved: slides/slide_01:18:48.jpg\n",
            "02:01:48\n",
            "Saved: slides/slide_01:21:48.jpg\n",
            "02:01:56\n",
            "Saved: slides/slide_01:21:56.jpg\n",
            "02:02:18\n",
            "Saved: slides/slide_01:22:18.jpg\n",
            "02:02:30\n",
            "Saved: slides/slide_01:22:30.jpg\n",
            "02:02:32\n",
            "Saved: slides/slide_01:22:32.jpg\n",
            "02:04:14\n",
            "Saved: slides/slide_01:24:14.jpg\n",
            "02:04:20\n",
            "Saved: slides/slide_01:24:20.jpg\n",
            "02:04:22\n",
            "Saved: slides/slide_01:24:22.jpg\n",
            "02:08:34\n",
            "Saved: slides/slide_01:28:34.jpg\n",
            "02:11:20\n",
            "Saved: slides/slide_01:31:20.jpg\n",
            "02:12:06\n",
            "Saved: slides/slide_01:32:06.jpg\n",
            "02:13:10\n",
            "Saved: slides/slide_01:33:10.jpg\n",
            "02:13:12\n",
            "Saved: slides/slide_01:33:12.jpg\n",
            "02:16:26\n",
            "Saved: slides/slide_01:36:26.jpg\n",
            "02:16:28\n",
            "Saved: slides/slide_01:36:28.jpg\n",
            "02:16:30\n",
            "Saved: slides/slide_01:36:30.jpg\n",
            "02:16:32\n",
            "Saved: slides/slide_01:36:32.jpg\n",
            "02:16:34\n",
            "Saved: slides/slide_01:36:34.jpg\n",
            "02:16:36\n",
            "Saved: slides/slide_01:36:36.jpg\n",
            "02:16:40\n",
            "Saved: slides/slide_01:36:40.jpg\n",
            "02:16:48\n",
            "Saved: slides/slide_01:36:48.jpg\n",
            "02:17:00\n",
            "Saved: slides/slide_01:37:00.jpg\n",
            "02:17:18\n",
            "Saved: slides/slide_01:37:18.jpg\n",
            "02:18:04\n",
            "Saved: slides/slide_01:38:04.jpg\n",
            "02:18:06\n",
            "Saved: slides/slide_01:38:06.jpg\n",
            "02:18:08\n",
            "Saved: slides/slide_01:38:08.jpg\n",
            "02:18:10\n",
            "Saved: slides/slide_01:38:10.jpg\n",
            "02:18:14\n",
            "Saved: slides/slide_01:38:14.jpg\n",
            "02:18:20\n",
            "Saved: slides/slide_01:38:20.jpg\n",
            "02:18:24\n",
            "Saved: slides/slide_01:38:24.jpg\n",
            "02:18:30\n",
            "Saved: slides/slide_01:38:30.jpg\n",
            "02:18:34\n",
            "Saved: slides/slide_01:38:34.jpg\n",
            "02:18:36\n",
            "Saved: slides/slide_01:38:36.jpg\n",
            "02:18:38\n",
            "Saved: slides/slide_01:38:38.jpg\n",
            "02:18:44\n",
            "Saved: slides/slide_01:38:44.jpg\n",
            "02:19:10\n",
            "Saved: slides/slide_01:39:10.jpg\n",
            "02:19:20\n",
            "Saved: slides/slide_01:39:20.jpg\n",
            "02:19:24\n",
            "Saved: slides/slide_01:39:24.jpg\n",
            "02:19:50\n",
            "Saved: slides/slide_01:39:50.jpg\n",
            "02:20:54\n",
            "Saved: slides/slide_01:40:54.jpg\n",
            "02:21:36\n",
            "Saved: slides/slide_01:41:36.jpg\n",
            "02:21:38\n",
            "Saved: slides/slide_01:41:38.jpg\n",
            "02:21:40\n",
            "Saved: slides/slide_01:41:40.jpg\n",
            "02:21:42\n",
            "Saved: slides/slide_01:41:42.jpg\n",
            "02:21:44\n",
            "Saved: slides/slide_01:41:44.jpg\n",
            "02:21:50\n",
            "Saved: slides/slide_01:41:50.jpg\n",
            "Slide changes detected at: ['00:40:26', '00:40:56', '00:41:18', '00:41:32', '00:42:52', '00:46:00', '00:48:12', '00:48:18', '00:48:20', '00:48:40', '00:48:54', '00:49:10', '00:49:40', '00:49:56', '00:50:00', '00:50:20', '00:50:32', '00:50:40', '00:50:46', '00:50:48', '00:54:06', '00:55:20', '00:58:38', '00:59:12', '01:00:12', '01:00:56', '01:00:58', '01:01:00', '01:01:06', '01:01:08', '01:01:10', '01:01:12', '01:01:14', '01:01:20', '01:01:50', '01:03:38', '01:05:28', '01:10:24', '01:11:08', '01:11:20', '01:11:36', '01:14:18', '01:15:26', '01:15:48', '01:15:56', '01:16:28', '01:18:06', '01:18:48', '01:21:48', '01:21:56', '01:22:18', '01:22:30', '01:22:32', '01:24:14', '01:24:20', '01:24:22', '01:28:34', '01:31:20', '01:32:06', '01:33:10', '01:33:12', '01:36:26', '01:36:28', '01:36:30', '01:36:32', '01:36:34', '01:36:36', '01:36:40', '01:36:48', '01:37:00', '01:37:18', '01:38:04', '01:38:06', '01:38:08', '01:38:10', '01:38:14', '01:38:20', '01:38:24', '01:38:30', '01:38:34', '01:38:36', '01:38:38', '01:38:44', '01:39:10', '01:39:20', '01:39:24', '01:39:50', '01:40:54', '01:41:36', '01:41:38', '01:41:40', '01:41:42', '01:41:44', '01:41:50']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"detected slides {len(slide_changes)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyUQrIWK1Tpc",
        "outputId": "4fb8afe8-c558-42be-e2c9-9afa61ca9a91"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "detected slides 94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio extraction"
      ],
      "metadata": {
        "id": "NNAVDti0a1Cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "id": "4tHPDl3Wa36U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f7571e-a264-4b20-b320-9669aee64775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-md7it0l5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-md7it0l5\n",
            "  Resolved https://github.com/openai/whisper.git to commit e58f28804528831904c3b6f2c0e473f346223433\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801358 sha256=49844c9dd639d33a3545d2d5709fb6161941f8816492d7809b18e01b583064b6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1ohld9ip/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231117 tiktoken-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "def transcribe_video(video_path, model_size='base'):\n",
        "    model = whisper.load_model(model_size)\n",
        "    result = model.transcribe(video_path)\n",
        "    return result"
      ],
      "metadata": {
        "id": "0fIvPrh4a8KU"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interleave_transcription_with_slides(transcription, slide_changes):\n",
        "    interleaved_data = []\n",
        "    current_slide = 0\n",
        "\n",
        "    for segment in transcription['segments']:\n",
        "        # Find the next slide change that occurs after this segment starts\n",
        "        while current_slide < len(slide_changes) and slide_changes[current_slide] <= segment['start']:\n",
        "            interleaved_data.append({'type': 'slide_change', 'timestamp': slide_changes[current_slide]})\n",
        "            current_slide += 1\n",
        "\n",
        "        # Add the transcribed text\n",
        "        interleaved_data.append({'type': 'transcription', 'timestamp': segment['start'], 'text': segment['text']})\n",
        "\n",
        "    # Handle any remaining slide changes\n",
        "    while current_slide < len(slide_changes):\n",
        "        interleaved_data.append({'type': 'slide_change', 'timestamp': slide_changes[current_slide]})\n",
        "        current_slide += 1\n",
        "\n",
        "    return interleaved_data"
      ],
      "metadata": {
        "id": "cw0oBthdbBJo"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#pdf or docx creation"
      ],
      "metadata": {
        "id": "bqXpP6KDbPIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMh1C3O0bjHn",
        "outputId": "69f36785-7060-4d23-d19c-55a38e17e076"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/239.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m235.5/239.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.5.0)\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "from docx.shared import Pt, Inches, Cm\n",
        "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
        "from docx.enum.section import WD_SECTION_START\n",
        "\n",
        "\n",
        "def create_document(interleaved_data, video_path, slides_folder='slides'):\n",
        "    # Extract base name and remove extension to form the DOCX file name\n",
        "    base_name = os.path.basename(video_path)\n",
        "    file_name_without_ext = os.path.splitext(base_name)[0]\n",
        "    output_file = f'{file_name_without_ext}.docx'\n",
        "\n",
        "    doc = Document()\n",
        "\n",
        "    style = doc.styles['Normal']\n",
        "    style.paragraph_format.line_spacing = 1  # Single line spacing\n",
        "    style.paragraph_format.space_before = Pt(0)\n",
        "    style.paragraph_format.space_after = Pt(0)\n",
        "\n",
        "    for item in interleaved_data:\n",
        "        if item['type'] == 'slide_change':\n",
        "      # Add slide image\n",
        "            slide_image_path = f\"{slides_folder}/slide_{item['timestamp']}.jpg\"\n",
        "            p = doc.add_paragraph()\n",
        "            try:\n",
        "                p.add_run().add_picture(slide_image_path, width=Inches(6))  # Adjust the width as needed\n",
        "            except Exception as e:\n",
        "                p.add_run(f\"Could not load slide image: {slide_image_path}\")\n",
        "        else:\n",
        "             # Clean up the transcribed text\n",
        "            cleaned_text = item['text'].strip().replace('\\n', ' ')\n",
        "            # Add the cleaned text to the document\n",
        "            p = doc.add_paragraph(cleaned_text)\n",
        "            # Adjust paragraph formatting as needed\n",
        "            p.paragraph_format.line_spacing = 1  # Single line spacing\n",
        "            p.paragraph_format.space_before = Pt(0)\n",
        "            p.paragraph_format.space_after = Pt(0)\n",
        "\n",
        "    doc.save(output_file)\n",
        "    print(f\"Document saved as: {output_file}\")\n",
        "\n",
        "\n",
        "def convert_timestamp_to_seconds(timestamp_str):\n",
        "    parts = timestamp_str.split(':')\n",
        "    if len(parts) == 3:\n",
        "        hours, minutes, seconds = map(int, parts)\n",
        "        return hours * 3600 + minutes * 60 + seconds\n",
        "    elif len(parts) == 2:\n",
        "        minutes, seconds = map(int, parts)\n",
        "        return minutes * 60 + seconds\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid timestamp format: {timestamp_str}\")\n",
        "\n",
        "def interleave_transcription_with_slides(transcription, slide_changes):\n",
        "    # Convert slide change timestamps to seconds\n",
        "    slide_changes_seconds = [convert_timestamp_to_seconds(ts) for ts in slide_changes]\n",
        "\n",
        "    interleaved_data = []\n",
        "    current_slide = 0\n",
        "\n",
        "    for segment in transcription['segments']:\n",
        "        # Find the next slide change that occurs after this segment starts\n",
        "        while current_slide < len(slide_changes_seconds) and slide_changes_seconds[current_slide] <= segment['start']:\n",
        "            interleaved_data.append({'type': 'slide_change', 'timestamp': slide_changes[current_slide]})\n",
        "            current_slide += 1\n",
        "\n",
        "        # Add the transcribed text\n",
        "        interleaved_data.append({'type': 'transcription', 'timestamp': segment['start'], 'text': segment['text']})\n",
        "\n",
        "    # Handle any remaining slide changes\n",
        "    while current_slide < len(slide_changes_seconds):\n",
        "        interleaved_data.append({'type': 'slide_change', 'timestamp': slide_changes[current_slide]})\n",
        "        current_slide += 1\n",
        "\n",
        "    return interleaved_data\n",
        "\n",
        "# Transcribe video\n",
        "transcription = transcribe_video(output_video_path)\n",
        "\n",
        "# Interleave transcription with slide changes\n",
        "interleaved_data = interleave_transcription_with_slides(transcription, slide_changes)\n",
        "\n",
        "# Create DOCX document\n",
        "create_document(interleaved_data, output_video_path)"
      ],
      "metadata": {
        "id": "Z1sK46IiboN8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2325fc8-3798-4d2d-e95d-708fcc5f323a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document saved as: 9_Semantic_Segmentation_converted.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bOAgSizs2nD",
        "outputId": "0abf35d6-2ab8-4f50-d0f4-3d842eebe1ef"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9_Semantic_Segmentation_converted.mp4  converted_video.mp4  LessonsExtractor.ipynb  \u001b[0m\u001b[01;34mslides\u001b[0m/\n",
            "9_Semantic_Segmentation.mp4            CSR-20221124.mp4     output.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "eliminate the slides images after having generated the docx output"
      ],
      "metadata": {
        "id": "s87R8Ymqum4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf /content/drive/MyDrive/lessonsExtractor/slides\n"
      ],
      "metadata": {
        "id": "j2xchC3lt87G"
      },
      "execution_count": 68,
      "outputs": []
    }
  ]
}